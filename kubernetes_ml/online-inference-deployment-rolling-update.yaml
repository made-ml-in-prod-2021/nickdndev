apiVersion: apps/v1
kind: Deployment
metadata:
  name: online-inference-ml
  labels:
    app: online-inference-ml
spec:
  replicas: 4
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 50%
      maxUnavailable: 50%
  selector:
    matchLabels:
      app: online-inference-ml
  template:
    metadata:
      name: online-inference-ml
      labels:
        app: online-inference-ml
    spec:
      containers:
        - image: nickml/online_inference:v1
          name: online-inference-ml
          ports:
            - containerPort: 8000
          resources:
            requests:
              memory: "64Mi"
              cpu: "250m"
            limits:
              memory: "128Mi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8000
            failureThreshold: 1
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /healthz
              port: 8000
            initialDelaySeconds: 15
            periodSeconds: 3
          startupProbe:
            httpGet:
              path: /healthz
              port: 8000
            failureThreshold: 3
            periodSeconds: 10

